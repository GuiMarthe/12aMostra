{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial em Tensorflow: Regressão Linear\n",
    "\n",
    "Nesse tutorial vamos montar um modelo de regressão linear usando a biblioteca [Tensorflow](https://www.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import util\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar um dataset bem simples: [Fire and Theft in Chicago](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/frame.html)\n",
    "\n",
    "As obervações são pares $(X,Y)$ em que\n",
    "\n",
    "- $X =$ incêncios por 1000 moradías\n",
    "- $Y =$ roubos por 1000 habitantes\n",
    "\n",
    "referentes a cidade de Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos olhar o começo dessa tabela\n",
    "df = pd.read_excel('data/fire_theft.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E também podemos ver algumas estatísticas descritivas básicas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transformando o dataset numa matrix\n",
    "data = df.as_matrix()\n",
    "data = data.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de montar o modelo vamos definir todos os **Hyper parametros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = data.shape[0]\n",
    "learning_rate=0.001\n",
    "num_epochs=101\n",
    "show_epoch=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph e Session são duas classes centrais no tensorflow.\n",
    "\n",
    "Nós montamos as operações na classe Graph (o grafo de computação) e executamos essas operações dentro de uma Session.\n",
    "\n",
    "- Sempre existe um grafo default.\n",
    "\n",
    "- Quando usamos tf.Graph.as_default sobrescrevemos o grafo default pelo grafo definido no contexto.\n",
    "\n",
    "- Um modo interativo de se rodar um grafo é por meio da tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos definir a regressão linear no grafo default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "\n",
    "# criando os placeholders para o par (X, Y)\n",
    "tf_number_fire = tf.placeholder(tf.float32, shape=[], name=\"X\")\n",
    "tf_number_theft = tf.placeholder(tf.float32, shape=[], name=\"Y\")\n",
    "\n",
    "# definindo os pesos do modelo. Ambos são inicializados com 0.\n",
    "tf_weight = tf.get_variable(\"w\", dtype=tf.float32, initializer=0.)\n",
    "tf_bias = tf.get_variable(\"b\", dtype=tf.float32, initializer=0.)\n",
    "\n",
    "# criando a predição do modelo: prediction = w*x +b\n",
    "tf_prediction = (tf_weight * tf_number_fire) + tf_bias\n",
    "\n",
    "# Definindo a função de custo como\n",
    "# o erro quadrático médio: (preiction -Y)^2\n",
    "tf_loss = tf.square(tf_prediction - tf_number_theft)\n",
    "    \n",
    "    \n",
    "#Definindo o otimizador para fazer o SGD\n",
    "tf_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "tf_optimizer = tf_opt.minimize(tf_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Como temos poucos dados (42 observações) podemos treinar o modelo passando por cada uma das observações uma a uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start training\\n')\n",
    "session.run(tf.global_variables_initializer())\n",
    "step = 0\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in data:\n",
    "        feed_dict = {tf_number_fire: x,\n",
    "                    tf_number_theft: y}\n",
    "        _,loss,w,b = session.run([tf_optimizer,tf_loss, tf_weight, tf_bias], feed_dict=feed_dict)\n",
    "        total_loss += loss\n",
    "\n",
    "    if i % show_epoch == 0:\n",
    "        print(\"\\nEpoch {0}: {1}\".format(i, total_loss/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Treinado o modelo, temos os novos valores para $w$ e $b$.\n",
    "\n",
    "Assim podemos calcular o [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) e plotar a reta resultante\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = util.r_squared(data,w,b)\n",
    "util.plot_line(data, w, b, \"Linear Regression with MSE\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O código acima pode ser melhorado. \n",
    "\n",
    "Podemos encapsular os hyper parametros numa classe. Assim como o modelo de regressão linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \"\"\"\n",
    "    Class to hold all model hyperparams.\n",
    "    :type learning_rate: float\n",
    "    :type delta: float\n",
    "    :type huber: boolean\n",
    "    :type num_epochs: int\n",
    "    :type show_epoch: int\n",
    "    :type log_path: None or str\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 learning_rate=0.001,\n",
    "                 delta=1.0,\n",
    "                 huber=False,\n",
    "                 num_epochs=101,\n",
    "                 show_epoch=10,\n",
    "                 log_path=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.delta = delta\n",
    "        self.huber = huber\n",
    "        self.num_epochs = num_epochs\n",
    "        self.show_epoch = show_epoch\n",
    "        if log_path is None:\n",
    "            self.log_path = util.get_log_path()\n",
    "        else:\n",
    "            self.log_path = log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    Class for the linear regression model\n",
    "    \n",
    "    :type config: Config\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.learning_rate = config.learning_rate\n",
    "        self.delta = config.delta\n",
    "        self.huber = config.huber\n",
    "        self.log_path = config.log_path\n",
    "        self.build_graph()\n",
    "\n",
    "    def create_placeholders(self):\n",
    "        \"\"\"\n",
    "        Method for creating placeholders for input X (number of fire)\n",
    "        and label Y (number of theft).\n",
    "        \"\"\"\n",
    "        self.number_fire = tf.placeholder(tf.float32, shape=[], name=\"X\")\n",
    "        self.number_theft = tf.placeholder(tf.float32, shape=[], name=\"Y\")\n",
    "\n",
    "    def create_variables(self):\n",
    "        \"\"\"\n",
    "        Method for creating weight and bias variables.\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"Weights\"):\n",
    "            self.weight = tf.get_variable(\"w\", dtype=tf.float32, initializer=0.)\n",
    "            self.bias = tf.get_variable(\"b\", dtype=tf.float32, initializer=0.)\n",
    "\n",
    "    def create_summaries(self):\n",
    "        \"\"\"\n",
    "        Method to create the histogram summaries for all variables\n",
    "        \"\"\"\n",
    "        tf.summary.histogram('weights_summ', self.weight)\n",
    "        tf.summary.histogram('bias_summ', self.bias)\n",
    "\n",
    "    def create_prediction(self):\n",
    "        \"\"\"\n",
    "        Method for creating the linear regression prediction.\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"linear-model\"):\n",
    "            self.prediction = (self.number_fire * self.weight) + self.bias\n",
    "\n",
    "    def create_MSE_loss(self):\n",
    "        \"\"\"\n",
    "        Method for creating the mean square error loss function.\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.loss = tf.square(self.prediction - self.number_theft)\n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "    def create_Huber_loss(self):\n",
    "        \"\"\"\n",
    "        Method for creating the Huber loss function.\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            residual = tf.abs(self.prediction - self.number_theft)\n",
    "            condition = tf.less(residual, self.delta)\n",
    "            small_residual = 0.5 * tf.square(residual)\n",
    "            large_residual = self.delta * residual - 0.5 * tf.square(self.delta)\n",
    "            self.loss = tf.where(condition, small_residual, large_residual)\n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        \"\"\"\n",
    "        Method to create the optimizer of the graph\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"optimizer\"):\n",
    "            opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "            self.optimizer = opt.minimize(self.loss)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        Method to build the computation graph in tensorflow\n",
    "        \"\"\"\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.create_placeholders()\n",
    "            self.create_variables()\n",
    "            self.create_summaries()\n",
    "            self.create_prediction()\n",
    "            if self.huber:\n",
    "                self.create_Huber_loss()\n",
    "            else:\n",
    "                self.create_MSE_loss()\n",
    "            self.create_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse modelo definimos dois tipos de função de erro. Uma delas é chamada de [Huber loss](https://en.wikipedia.org/wiki/Huber_loss).\n",
    "\n",
    "Relembrando a função:\n",
    "\n",
    "   \n",
    "- $L_{\\delta}(y,f(x)) =  \\frac{1}{2}(y-f(x))^{2}$ se $|y-f(x)|\\leq \\delta$\n",
    "\n",
    "- $L_{\\delta}(y,f(x)) =  \\delta|y-f(x)| -\\frac{1}{2}\\delta^{2}$ caso contrário \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training(model, config, data, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to train the linear regression model\n",
    "\n",
    "    :type model: LinearRegression\n",
    "    :type config: Config\n",
    "    :type data: np array\n",
    "    :type verbose: boolean\n",
    "    :rtype total_loss: float\n",
    "    :rtype w: float\n",
    "    :rtype b: float\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "    num_epochs = config.num_epochs\n",
    "    show_epoch = config.show_epoch\n",
    "    log_path = model.log_path\n",
    "    with tf.Session(graph=model.graph) as sess:\n",
    "        if verbose:\n",
    "            print('Start training\\n')\n",
    "        # functions to write the tensorboard logs\n",
    "        summary_writer = tf.summary.FileWriter(log_path,sess.graph)\n",
    "        all_summaries = tf.summary.merge_all()\n",
    "        # initializing variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        step = 0\n",
    "        for i in range(num_epochs): # run num_epochs epochs\n",
    "            total_loss = 0\n",
    "            for x, y in data:\n",
    "                step += 1\n",
    "                \n",
    "                feed_dict = {model.number_fire: x,\n",
    "                             model.number_theft: y}\n",
    "                \n",
    "                _,loss,summary,w,b = sess.run([model.optimizer, # run optimizer to perform minimization\n",
    "                                               model.loss,\n",
    "                                               all_summaries,\n",
    "                                               model.weight,\n",
    "                                               model.bias], feed_dict=feed_dict)\n",
    "\n",
    "                #writing the log\n",
    "                summary_writer.add_summary(summary,step)\n",
    "                summary_writer.flush()\n",
    "                \n",
    "                total_loss += loss\n",
    "            if i % show_epoch == 0:\n",
    "                print(\"\\nEpoch {0}: {1}\".format(i, total_loss/num_samples))\n",
    "    if verbose:\n",
    "        print(\"\\n========= For TensorBoard visualization type ===========\")\n",
    "        print(\"\\ntensorboard  --logdir={}\\n\".format(log_path))\n",
    "    return total_loss,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = Config()\n",
    "my_model = LinearRegression(my_config)\n",
    "l,w,b = run_training(my_model, my_config, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tensorboard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) é uma ótima ferramenta de visualização. \n",
    "\n",
    "Podemos ver o grafo de computação e ver certas metrícas ao longo do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard  --logdir="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
